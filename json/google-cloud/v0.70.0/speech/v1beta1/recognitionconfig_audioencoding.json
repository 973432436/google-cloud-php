{"id":"speech\/v1beta1\/recognitionconfig_audioencoding","type":"","title":"Google\\Cloud\\Speech\\V1beta1\\RecognitionConfig_AudioEncoding","name":"RecognitionConfig_AudioEncoding","description":"<p>Audio encoding of the data sent in the audio message. All encodings support\nonly 1 channel (mono) audio. Only <code>FLAC<\/code> includes a header that describes\nthe bytes of audio that follow the header. The other encodings are raw\naudio bytes with no header.<\/p>\n<p>For best results, the audio source should be captured and transmitted using\na lossless encoding (<code>FLAC<\/code> or <code>LINEAR16<\/code>). Recognition accuracy may be\nreduced if lossy codecs (such as AMR, AMR_WB and MULAW) are used to capture\nor transmit the audio, particularly if background noise is present.<\/p>\n<p>Protobuf enum <code>Google\\Cloud\\Speech\\V1beta1\\RecognitionConfig\\AudioEncoding<\/code><\/p>","examples":[],"resources":[],"methods":[]}